\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Ch3: Linear Regression},
            pdfauthor={Kylie},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Ch3: Linear Regression}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \subtitle{Lab}
  \author{Kylie}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{06/04/2019}


\begin{document}
\maketitle

\hypertarget{simple-linear-regression}{%
\section{3.6.2 Simple Linear
Regression}\label{simple-linear-regression}}

Using the \texttt{lm()} function to fit a simple linear regression
model. The basic syntax is \texttt{lm(y\ ∼\ x,\ data)}, where \texttt{y}
is the response, \texttt{x} is the predictor, and \texttt{data} is the
data set in which these two variables are kept.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Looking at the data briefly:}
\CommentTok{#fix(Boston) # or View(Boston)}
\KeywordTok{names}\NormalTok{(Boston) }\CommentTok{# lists the variable names}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "crim"    "zn"      "indus"   "chas"    "nox"     "rm"      "age"    
##  [8] "dis"     "rad"     "tax"     "ptratio" "black"   "lstat"   "medv"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as_tibble}\NormalTok{(Boston) }\CommentTok{# alternative way to view a subsection of the data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 506 x 14
##       crim    zn indus  chas   nox    rm   age   dis   rad   tax ptratio
##      <dbl> <dbl> <dbl> <int> <dbl> <dbl> <dbl> <dbl> <int> <dbl>   <dbl>
##  1 0.00632  18    2.31     0 0.538  6.58  65.2  4.09     1   296    15.3
##  2 0.0273    0    7.07     0 0.469  6.42  78.9  4.97     2   242    17.8
##  3 0.0273    0    7.07     0 0.469  7.18  61.1  4.97     2   242    17.8
##  4 0.0324    0    2.18     0 0.458  7.00  45.8  6.06     3   222    18.7
##  5 0.0690    0    2.18     0 0.458  7.15  54.2  6.06     3   222    18.7
##  6 0.0298    0    2.18     0 0.458  6.43  58.7  6.06     3   222    18.7
##  7 0.0883   12.5  7.87     0 0.524  6.01  66.6  5.56     5   311    15.2
##  8 0.145    12.5  7.87     0 0.524  6.17  96.1  5.95     5   311    15.2
##  9 0.211    12.5  7.87     0 0.524  5.63 100    6.08     5   311    15.2
## 10 0.170    12.5  7.87     0 0.524  6.00  85.9  6.59     5   311    15.2
## # ... with 496 more rows, and 3 more variables: black <dbl>, lstat <dbl>,
## #   medv <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# using the lm() function to fit a simple linear regression lm()}
\CommentTok{# model, with medv as the response and lstat as the predictor:}
\NormalTok{lm_fit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(medv∼lstat, }\DataTypeTok{data=}\NormalTok{Boston)}

\NormalTok{lm_fit }\CommentTok{# outputs some basic information about the model}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ lstat, data = Boston)
## 
## Coefficients:
## (Intercept)        lstat  
##       34.55        -0.95
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(lm_fit) }\CommentTok{# outputs more detail including pvalues and standard errors for the coefficients, as well as the R2 statistic and F-statistic for the model.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ lstat, data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.168  -3.990  -1.318   2.034  24.500 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 34.55384    0.56263   61.41   <2e-16 ***
## lstat       -0.95005    0.03873  -24.53   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.216 on 504 degrees of freedom
## Multiple R-squared:  0.5441, Adjusted R-squared:  0.5432 
## F-statistic: 601.6 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(lm_fit) }\CommentTok{# shows what other pieces of information are stored in lm_fit.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "coefficients"  "residuals"     "effects"       "rank"         
##  [5] "fitted.values" "assign"        "qr"            "df.residual"  
##  [9] "xlevels"       "call"          "terms"         "model"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Although we can extract these quantities by name—e.g. lm.fit$coefficients—it is safer to use the extractor functions like coef() to access them.}
\KeywordTok{coef}\NormalTok{(lm_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)       lstat 
##  34.5538409  -0.9500494
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{confint}\NormalTok{(lm_fit) }\CommentTok{# confidence interval for the coefficient estimates}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 2.5 %     97.5 %
## (Intercept) 33.448457 35.6592247
## lstat       -1.026148 -0.8739505
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(lm_fit, }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{lstat =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{15}\NormalTok{)), }\DataTypeTok{interval =} \StringTok{"confidence"}\NormalTok{) }\CommentTok{# produces confidence intervals for the prediction of medv for a given value of lstat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit      lwr      upr
## 1 29.80359 29.00741 30.59978
## 2 25.05335 24.47413 25.63256
## 3 20.30310 19.73159 20.87461
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(lm_fit, }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{lstat =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{15}\NormalTok{)), }\DataTypeTok{interval =} \StringTok{"prediction"}\NormalTok{) }\CommentTok{# produces prediction intervals for the prediction of medv for a given value of lstat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit       lwr      upr
## 1 29.80359 17.565675 42.04151
## 2 25.05335 12.827626 37.27907
## 3 20.30310  8.077742 32.52846
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# plotting data and fitted line}
\KeywordTok{attach}\NormalTok{(Boston)}
\KeywordTok{plot}\NormalTok{(lstat, medv)}
\KeywordTok{abline}\NormalTok{ (lm_fit)}
\CommentTok{# trying different linewidths, symbol shapes and colours}
\KeywordTok{abline}\NormalTok{(lm_fit, }\DataTypeTok{lwd =}\DecValTok{3}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(lm_fit, }\DataTypeTok{lwd =}\DecValTok{3}\NormalTok{, }\DataTypeTok{col =}\StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(lstat, medv, }\DataTypeTok{col =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(lstat, medv, }\DataTypeTok{pch =}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(lstat, medv, }\DataTypeTok{pch =} \StringTok{"+"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression-4.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{ (}\DecValTok{1}\OperatorTok{:}\DecValTok{20}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\DecValTok{20}\NormalTok{, }\DataTypeTok{pch =}\DecValTok{1}\OperatorTok{:}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression-5.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ggplot alternative:}
\KeywordTok{theme_set}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{()) }\CommentTok{# setting theme to black and white}

\KeywordTok{ggplot}\NormalTok{(Boston, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ lstat, }\DataTypeTok{y =}\NormalTok{ medv)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{, }\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression-6.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# trying different linewidths, symbol shapes and colours}
\KeywordTok{ggplot}\NormalTok{(Boston, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ lstat, }\DataTypeTok{y =}\NormalTok{ medv)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{, }\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{3}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression-7.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(Boston, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ lstat, }\DataTypeTok{y =}\NormalTok{ medv)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{color =} \StringTok{"red"}\NormalTok{, }\DataTypeTok{shape =} \DecValTok{21}\NormalTok{, }\DataTypeTok{size =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression-8.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(Boston, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ lstat, }\DataTypeTok{y =}\NormalTok{ medv)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{shape =} \StringTok{"+"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression-9.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \DecValTok{1}\OperatorTok{:}\DecValTok{20}\NormalTok{, }\DataTypeTok{y =} \DecValTok{1}\OperatorTok{:}\DecValTok{20}\NormalTok{), }\DataTypeTok{shape =} \DecValTok{1}\OperatorTok{:}\DecValTok{20}\NormalTok{, }\DataTypeTok{size =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression-10.pdf}

Need to look up the difference between confidence intervals and
prediction intervals.

Four diagnostic plots are automatically produced by applying the
\texttt{plot()} function directly to the output from \texttt{lm()}.
Detailed information about these plots is available at:
\url{https://www.andrew.cmu.edu/user/achoulde/94842/homework/regression_diagnostics.html}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)) }\CommentTok{# divides the plotting region into a 2 × 2 grid of panels}
\KeywordTok{plot}\NormalTok{(lm_fit) }\CommentTok{# plotting diagnostic plots}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression_diag-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{predict}\NormalTok{(lm_fit), }\KeywordTok{residuals}\NormalTok{(lm_fit))}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{predict}\NormalTok{(lm_fit), }\KeywordTok{rstudent}\NormalTok{(lm_fit))}
\CommentTok{# On the basis of the residual plots, there is some evidence of non-linearity.}

\KeywordTok{plot}\NormalTok{(}\KeywordTok{hatvalues}\NormalTok{(lm_fit)) }\CommentTok{# computes leverage statistics for any number of predictors}
\KeywordTok{which.max}\NormalTok{(}\KeywordTok{hatvalues}\NormalTok{(lm_fit)) }\CommentTok{# tells us which observation has the largest leverage statistic}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 375 
## 375
\end{verbatim}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/simple_regression_diag-2.pdf}

\hypertarget{multiple-linear-regression}{%
\section{3.6.3 Multiple Linear
Regression}\label{multiple-linear-regression}}

Using the \texttt{lm()} function to fit a multiple linear regression
model. The syntax is \texttt{lm(y\ ∼\ x1\ +\ x2\ +\ x3,\ data)}, where
\texttt{y} is the response, \texttt{x1,\ x2,\ x3} are the predictors,
and \texttt{data} is the data set in which these two variables are kept.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_fit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(medv ∼ lstat }\OperatorTok{+}\StringTok{ }\NormalTok{age, }\DataTypeTok{data =}\NormalTok{ Boston) }\CommentTok{# fitting multiple linear regression model with lstat and age as predictors and medv as the response}
\KeywordTok{summary}\NormalTok{(lm_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ lstat + age, data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.981  -3.978  -1.283   1.968  23.158 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 33.22276    0.73085  45.458  < 2e-16 ***
## lstat       -1.03207    0.04819 -21.416  < 2e-16 ***
## age          0.03454    0.01223   2.826  0.00491 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.173 on 503 degrees of freedom
## Multiple R-squared:  0.5513, Adjusted R-squared:  0.5495 
## F-statistic:   309 on 2 and 503 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_fit_all <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(medv ∼., }\DataTypeTok{data =}\NormalTok{ Boston) }\CommentTok{# fitting multiple linear regression model with ALL predictors and medv as the response}
\KeywordTok{summary}\NormalTok{(lm_fit_all)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ ., data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.595  -2.730  -0.518   1.777  26.199 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***
## crim        -1.080e-01  3.286e-02  -3.287 0.001087 ** 
## zn           4.642e-02  1.373e-02   3.382 0.000778 ***
## indus        2.056e-02  6.150e-02   0.334 0.738288    
## chas         2.687e+00  8.616e-01   3.118 0.001925 ** 
## nox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***
## rm           3.810e+00  4.179e-01   9.116  < 2e-16 ***
## age          6.922e-04  1.321e-02   0.052 0.958229    
## dis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***
## rad          3.060e-01  6.635e-02   4.613 5.07e-06 ***
## tax         -1.233e-02  3.760e-03  -3.280 0.001112 ** 
## ptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***
## black        9.312e-03  2.686e-03   3.467 0.000573 ***
## lstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.745 on 492 degrees of freedom
## Multiple R-squared:  0.7406, Adjusted R-squared:  0.7338 
## F-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(lm_fit)}\OperatorTok{$}\NormalTok{r.sq }\CommentTok{# gives the R2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.5512689
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(lm_fit)}\OperatorTok{$}\NormalTok{sigma }\CommentTok{# gives the RSE (Residual Standard Error: Roughly speaking, RSE is the average amount that the response will deviate from the true regression line).}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6.173136
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{vif}\NormalTok{(lm_fit) }\CommentTok{# gives variance inflation factors}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    lstat      age 
## 1.569395 1.569395
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_fit1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(medv ∼. }\OperatorTok{-}\NormalTok{age, }\DataTypeTok{data =}\NormalTok{ Boston) }\CommentTok{# fitting all variables EXCEPT age}
\KeywordTok{summary}\NormalTok{(lm_fit1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ . - age, data = Boston)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.6054  -2.7313  -0.5188   1.7601  26.2243 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  36.436927   5.080119   7.172 2.72e-12 ***
## crim         -0.108006   0.032832  -3.290 0.001075 ** 
## zn            0.046334   0.013613   3.404 0.000719 ***
## indus         0.020562   0.061433   0.335 0.737989    
## chas          2.689026   0.859598   3.128 0.001863 ** 
## nox         -17.713540   3.679308  -4.814 1.97e-06 ***
## rm            3.814394   0.408480   9.338  < 2e-16 ***
## dis          -1.478612   0.190611  -7.757 5.03e-14 ***
## rad           0.305786   0.066089   4.627 4.75e-06 ***
## tax          -0.012329   0.003755  -3.283 0.001099 ** 
## ptratio      -0.952211   0.130294  -7.308 1.10e-12 ***
## black         0.009321   0.002678   3.481 0.000544 ***
## lstat        -0.523852   0.047625 -10.999  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.74 on 493 degrees of freedom
## Multiple R-squared:  0.7406, Adjusted R-squared:  0.7343 
## F-statistic: 117.3 on 12 and 493 DF,  p-value: < 2.2e-16
\end{verbatim}

\hypertarget{interaction-terms}{%
\section{3.6.4 Interaction Terms}\label{interaction-terms}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(}\KeywordTok{lm}\NormalTok{(medv ∼ lstat}\OperatorTok{*}\NormalTok{age, }\DataTypeTok{data =}\NormalTok{ Boston)) }\CommentTok{# includes lstat, age, and the interaction term lstat×age as predictors}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ lstat * age, data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.806  -4.045  -1.333   2.085  27.552 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 36.0885359  1.4698355  24.553  < 2e-16 ***
## lstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***
## age         -0.0007209  0.0198792  -0.036   0.9711    
## lstat:age    0.0041560  0.0018518   2.244   0.0252 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.149 on 502 degrees of freedom
## Multiple R-squared:  0.5557, Adjusted R-squared:  0.5531 
## F-statistic: 209.3 on 3 and 502 DF,  p-value: < 2.2e-16
\end{verbatim}

\hypertarget{non-linear-transformations-of-the-predictors}{%
\section{3.6.5 Non-linear Transformations of the
Predictors}\label{non-linear-transformations-of-the-predictors}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_fit2 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(medv ∼ lstat }\OperatorTok{+}\StringTok{ }\KeywordTok{I}\NormalTok{(lstat}\OperatorTok{^}\DecValTok{2}\NormalTok{)) }\CommentTok{# regression of medv onto lstat and lstat^2}
\KeywordTok{summary}\NormalTok{(lm_fit2) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ lstat + I(lstat^2))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.2834  -3.8313  -0.5295   2.3095  25.4148 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 42.862007   0.872084   49.15   <2e-16 ***
## lstat       -2.332821   0.123803  -18.84   <2e-16 ***
## I(lstat^2)   0.043547   0.003745   11.63   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.524 on 503 degrees of freedom
## Multiple R-squared:  0.6407, Adjusted R-squared:  0.6393 
## F-statistic: 448.5 on 2 and 503 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The near-zero p-value associated with the quadratic term suggests that it leads to an improved model.}

\NormalTok{lm_fit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(medv ∼ lstat) }
\KeywordTok{anova}\NormalTok{(lm_fit, lm_fit2) }\CommentTok{# to quantify the extent to which the quadratic fit is superior to the linear fit.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Model 1: medv ~ lstat
## Model 2: medv ~ lstat + I(lstat^2)
##   Res.Df   RSS Df Sum of Sq     F    Pr(>F)    
## 1    504 19472                                 
## 2    503 15347  1    4125.1 135.2 < 2.2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

``Here Model 1 represents the linear submodel containing only one
predictor, \texttt{lstat}, while Model 2 corresponds to the larger
quadratic model that has two predictors, \texttt{lstat} and
\texttt{lstat\^{}2}. The \texttt{anova()} function performs a hypothesis
test comparing the two models. The null hypothesis is that the two
models fit the data equally well, and the alternative hypothesis is that
the full model is superior. Here the F-statistic is 135 and the
associated p-value is virtually zero. This provides very clear evidence
that the model containing the predictors \texttt{lstat} and
\texttt{lstat\^{}2} is far superior to the model that only contains the
predictor \texttt{lstat}. This is not surprising, since earlier we saw
evidence for non-linearity in the relationship between \texttt{medv} and
\texttt{lstat}.''

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(lm_fit2)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Ch3_Linear_Regression_Lab_files/figure-latex/polynomial-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# there is little discernible pattern in the residuals.}

\NormalTok{lm_fit5 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(medv ∼ }\KeywordTok{poly}\NormalTok{(lstat, }\DecValTok{5}\NormalTok{)) }\CommentTok{# a fifth-order polynomial fit}
\KeywordTok{summary}\NormalTok{(lm_fit5)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ poly(lstat, 5))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.5433  -3.1039  -0.7052   2.0844  27.1153 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(>|t|)    
## (Intercept)       22.5328     0.2318  97.197  < 2e-16 ***
## poly(lstat, 5)1 -152.4595     5.2148 -29.236  < 2e-16 ***
## poly(lstat, 5)2   64.2272     5.2148  12.316  < 2e-16 ***
## poly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***
## poly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***
## poly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.215 on 500 degrees of freedom
## Multiple R-squared:  0.6817, Adjusted R-squared:  0.6785 
## F-statistic: 214.2 on 5 and 500 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(}\KeywordTok{lm}\NormalTok{(medv ∼ }\KeywordTok{log}\NormalTok{(rm), }\DataTypeTok{data =}\NormalTok{ Boston)) }\CommentTok{# log transformation of rm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ log(rm), data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -19.487  -2.875  -0.104   2.837  39.816 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  -76.488      5.028  -15.21   <2e-16 ***
## log(rm)       54.055      2.739   19.73   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.915 on 504 degrees of freedom
## Multiple R-squared:  0.4358, Adjusted R-squared:  0.4347 
## F-statistic: 389.3 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

\hypertarget{qualitative-predictors}{%
\section{3.6.6 Qualitative Predictors}\label{qualitative-predictors}}

Given a qualitative variable such as \texttt{Shelveloc} (which takes on
3 possible values, Bad, Medium, and Good), \texttt{R} generates dummy
variables automatically.

BUT ordering is important for \texttt{Shelveloc}, does it make a
difference if we transform it to a factor with values 1, 2 and 3, or is
ordering not important for linear regression?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as_tibble}\NormalTok{(Carseats)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 400 x 11
##    Sales CompPrice Income Advertising Population Price ShelveLoc   Age
##    <dbl>     <dbl>  <dbl>       <dbl>      <dbl> <dbl> <fct>     <dbl>
##  1  9.5        138     73          11        276   120 Bad          42
##  2 11.2        111     48          16        260    83 Good         65
##  3 10.1        113     35          10        269    80 Medium       59
##  4  7.4        117    100           4        466    97 Medium       55
##  5  4.15       141     64           3        340   128 Bad          38
##  6 10.8        124    113          13        501    72 Bad          78
##  7  6.63       115    105           0         45   108 Medium       71
##  8 11.8        136     81          15        425   120 Good         67
##  9  6.54       132    110           0        108   124 Medium       76
## 10  4.69       132    113           0        131   124 Medium       76
## # ... with 390 more rows, and 3 more variables: Education <dbl>,
## #   Urban <fct>, US <fct>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(Carseats)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Sales"       "CompPrice"   "Income"      "Advertising" "Population" 
##  [6] "Price"       "ShelveLoc"   "Age"         "Education"   "Urban"      
## [11] "US"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_fit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Sales ∼. }\OperatorTok{+}\StringTok{ }\NormalTok{Income}\OperatorTok{:}\NormalTok{Advertising }\OperatorTok{+}\StringTok{ }\NormalTok{Price}\OperatorTok{:}\NormalTok{Age, }\DataTypeTok{data =}\NormalTok{ Carseats) }\CommentTok{# multiple regression model that includes all predictors plus some interaction terms}
\KeywordTok{summary}\NormalTok{(lm_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.9208 -0.7503  0.0177  0.6754  3.3413 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(>|t|)    
## (Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***
## CompPrice           0.0929371  0.0041183  22.567  < 2e-16 ***
## Income              0.0108940  0.0026044   4.183 3.57e-05 ***
## Advertising         0.0702462  0.0226091   3.107 0.002030 ** 
## Population          0.0001592  0.0003679   0.433 0.665330    
## Price              -0.1008064  0.0074399 -13.549  < 2e-16 ***
## ShelveLocGood       4.8486762  0.1528378  31.724  < 2e-16 ***
## ShelveLocMedium     1.9532620  0.1257682  15.531  < 2e-16 ***
## Age                -0.0579466  0.0159506  -3.633 0.000318 ***
## Education          -0.0208525  0.0196131  -1.063 0.288361    
## UrbanYes            0.1401597  0.1124019   1.247 0.213171    
## USYes              -0.1575571  0.1489234  -1.058 0.290729    
## Income:Advertising  0.0007510  0.0002784   2.698 0.007290 ** 
## Price:Age           0.0001068  0.0001333   0.801 0.423812    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.011 on 386 degrees of freedom
## Multiple R-squared:  0.8761, Adjusted R-squared:  0.8719 
## F-statistic:   210 on 13 and 386 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#contrasts(Carseats$ShelveLoc)}
\end{Highlighting}
\end{Shaded}

\hypertarget{new-packagesfunctions}{%
\section{New packages/functions}\label{new-packagesfunctions}}

New packages/functions I've learnt during these exercises:

\begin{itemize}
\tightlist
\item
  \texttt{lm()}
\end{itemize}

\texttt{lm(y\ ∼\ x,\ data\ =\ data)}: fits \texttt{x}

\texttt{lm(y\ ∼\ x1\ +\ x2,\ data\ =\ data)}: fits \texttt{x2} and
\texttt{x1}

\texttt{lm(y\ ∼.,\ data\ =\ data)}: fits all variables in \texttt{data}

\texttt{lm(y\ ∼.\ -x1,\ data\ =\ data)}: fits all variables in
\texttt{data} except \texttt{x1}

\texttt{lm(y\ \textasciitilde{}\ x1:x2,\ data\ =\ data)}: includes the
interaction term \texttt{x1} x \texttt{x2} as a predictor.

\texttt{lm(y\ \textasciitilde{}\ x1*x2,\ data\ =\ data)}: includes
\texttt{x1}, \texttt{x2} and the interaction term \texttt{x1} x
\texttt{x2}; it is a shorthand for \texttt{lstat} + \texttt{age} +
\texttt{lstat:age}

\texttt{lm(y\ \textasciitilde{}\ poly(x,\ 5),\ data\ =\ data)}: fits
\texttt{x}, \texttt{x\^{}2}, \texttt{x\^{}3}, \texttt{x\^{}4} and
\texttt{x\^{}5}.

\begin{itemize}
\item
  \texttt{predict()}
\item
  \texttt{geom\_smooth()}
\item
  \texttt{residuals()}
\item
  \texttt{rstudent()}
\item
  \texttt{which.max()}: identifies the index of the largest element of a
  vector.
\item
  \texttt{hatvalues()}: need to find out what this does.
\item
  \texttt{I()}
\item
  \texttt{contrasts()}
\end{itemize}

\hypertarget{confit}{%
\subsection{\texorpdfstring{\texttt{confit}}{confit}}\label{confit}}

Computes confidence intervals for one or more parameters in a fitted
model.

\texttt{confint(object,\ parm,\ level\ =\ 0.95,\ \ldots{})}

Arguments/Inputs:

\begin{itemize}
\item
  object: a fitted model object.
\item
  parm: a specification of which parameters are to be given confidence
  intervals, either a vector of numbers or a vector of names. If
  missing, all parameters are considered.
\item
  level: the confidence level required (0.95 is the default).
\end{itemize}

Value/Output:

A matrix (or vector) with columns giving lower and upper confidence
limits for each parameter.


\end{document}
